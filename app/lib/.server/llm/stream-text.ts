import { convertToCoreMessages, streamText as _streamText, type Message } from 'ai';
import { MAX_TOKENS, type FileMap } from './constants';
import { DEFAULT_MODEL, DEFAULT_PROVIDER, MODIFICATIONS_TAG_NAME, PROVIDER_LIST, WORK_DIR } from '~/utils/constants';
import type { IProviderSetting } from '~/types/model';
import type { DesignScheme } from '~/types/design-scheme';
import { PromptLibrary } from '~/lib/common/prompt-library';
import { allowedHTMLElements } from '~/utils/markdown';
import { LLMManager } from '~/lib/modules/llm/manager';
import { createScopedLogger } from '~/utils/logger';
import { createFilesContext, extractPropertiesFromMessage } from './utils';

export type Messages = Message[];

export interface StreamingOptions extends Omit<Parameters<typeof _streamText>[0], 'model'> {
  supabaseConnection?: {
    isConnected: boolean;
    hasSelectedProject: boolean;
    credentials?: {
      anonKey?: string;
      supabaseUrl?: string;
    };
  };
}

const logger = createScopedLogger('stream-text');

export async function streamText(props: {
  messages: Omit<Message, 'id'>[];
  env?: Env;
  options?: StreamingOptions;
  apiKeys?: Record<string, string>;
  files?: FileMap;
  providerSettings?: Record<string, IProviderSetting>;
  promptId?: string;
  contextOptimization?: boolean;
  contextFiles?: FileMap;
  summary?: string;
  messageSliceId?: number;
  designScheme?: DesignScheme;
}) {
  const {
    messages,
    env: serverEnv,
    options,
    apiKeys,
    files,
    providerSettings,
    promptId,
    contextOptimization,
    contextFiles,
    summary,
    designScheme,
  } = props;
  let currentModel = DEFAULT_MODEL;
  let currentProvider = DEFAULT_PROVIDER.name;
  let processedMessages = messages.map((message) => {
    if (message.role === 'user') {
      const { model, provider, content } = extractPropertiesFromMessage(message);
      currentModel = model;
      currentProvider = provider;

      return { ...message, content };
    } else if (message.role == 'assistant') {
      let content = message.content;
      content = content.replace(/<div class=\\"__codinitThought__\\">.*?<\/div>/s, '');
      content = content.replace(/<div class=\\"__codinitThinking__\\"[^>]*>.*?<\/div>/gs, '');
      content = content.replace(/<think>.*?<\/think>/s, '');
      content = content.replace(/<codinitThinking[^>]*>.*?<\/codinitThinking>/gs, '');

      content = content.replace(
        /<codinitAction type="file" filePath="package-lock\.json">[\s\S]*?<\/codinitAction>/g,
        '[package-lock.json content removed]',
      );

      content = content.trim();

      return { ...message, content };
    }

    return message;
  });

  const provider = PROVIDER_LIST.find((p) => p.name === currentProvider) || DEFAULT_PROVIDER;
  const staticModels = LLMManager.getInstance().getStaticModelListFromProvider(provider);
  let modelDetails = staticModels.find((m) => m.name === currentModel);

  if (!modelDetails) {
    const modelsList = [
      ...(provider.staticModels || []),
      ...(await LLMManager.getInstance().getModelListFromProvider(provider, {
        apiKeys,
        providerSettings,
        serverEnv: serverEnv as any,
      })),
    ];

    if (!modelsList.length) {
      throw new Error(`No models found for provider ${provider.name}`);
    }

    modelDetails = modelsList.find((m) => m.name === currentModel);

    if (!modelDetails) {
      // Fallback to first model
      logger.warn(
        `MODEL [${currentModel}] not found in provider [${provider.name}]. Falling back to first model. ${modelsList[0].name}`,
      );
      modelDetails = modelsList[0];
    }
  }

  const dynamicMaxTokens = modelDetails && modelDetails.maxTokenAllowed ? modelDetails.maxTokenAllowed : MAX_TOKENS;

  let systemPrompt = PromptLibrary.getPromptFromLibrary(promptId || 'default', {
    cwd: WORK_DIR,
    allowedHtmlElements: allowedHTMLElements,
    modificationTagName: MODIFICATIONS_TAG_NAME,
    supabase: {
      isConnected: options?.supabaseConnection?.isConnected || false,
      hasSelectedProject: options?.supabaseConnection?.hasSelectedProject || false,
      credentials: options?.supabaseConnection?.credentials || undefined,
    },
  });

  if (contextFiles && contextOptimization) {
    const codeContext = createFilesContext(contextFiles, true);

    systemPrompt = `${systemPrompt}

Below is the artifact containing the context loaded into context buffer for you to have knowledge of and might need changes to fullfill current user request.
CONTEXT BUFFER:
---
${codeContext}
---
`;

    if (summary) {
      systemPrompt = `${systemPrompt}
      below is the chat history till now
CHAT SUMMARY:
---
${props.summary}
---
`;

      if (props.messageSliceId) {
        processedMessages = processedMessages.slice(props.messageSliceId);
      } else {
        const lastMessage = processedMessages.pop();

        if (lastMessage) {
          processedMessages = [lastMessage];
        }
      }
    }
  }

  const effectiveLockedFilePaths = new Set<string>();

  if (files) {
    for (const [filePath, fileDetails] of Object.entries(files)) {
      if (fileDetails?.isLocked) {
        effectiveLockedFilePaths.add(filePath);
      }
    }
  }

  if (effectiveLockedFilePaths.size > 0) {
    const lockedFilesListString = Array.from(effectiveLockedFilePaths)
      .map((filePath) => `- ${filePath}`)
      .join('\n');
    systemPrompt = `${systemPrompt}

IMPORTANT: The following files are locked and MUST NOT be modified in any way. Do not suggest or make any changes to these files. You can proceed with the request but DO NOT make any changes to these files specifically:
${lockedFilesListString}
---
`;
  } else {
    console.log('No locked files found from any source for prompt.');
  }

  if (designScheme) {
    systemPrompt = `${systemPrompt}

DESIGN PREFERENCES:
The user has the following design preferences that should guide your creation of UI components and designs:
- Color Palette (Light Mode):
  - Primary: ${designScheme.palette.light.primary}
  - Secondary: ${designScheme.palette.light.secondary}
  - Accent: ${designScheme.palette.light.accent}
  - Background: ${designScheme.palette.light.background}
  - Text: ${designScheme.palette.light.text}
- Color Palette (Dark Mode):
  - Primary: ${designScheme.palette.dark.primary}
  - Secondary: ${designScheme.palette.dark.secondary}
  - Accent: ${designScheme.palette.dark.accent}
  - Background: ${designScheme.palette.dark.background}
  - Text: ${designScheme.palette.dark.text}
- Typography: ${designScheme.font.join(', ')}
- Design Mode: ${designScheme.mode}
- Border Radius: ${designScheme.borderRadius}
- Shadow Style: ${designScheme.shadow}
- Spacing: ${designScheme.spacing}
- Design Features: ${designScheme.features.join(', ')}

Use these preferences when creating UI components, styling code, or suggesting design improvements.
`;
  }

  logger.info(`Sending llm call to ${provider.name} with model ${modelDetails.name}`);

  /*
   * Only pass tools that are properly implemented with valid Zod schemas.
   * Built-in tools from JSON don't have Zod validation, so we don't pass any tools
   * to avoid zod-to-json-schema conversion errors.
   */
  const allTools = {};

  logger.info(`Skipping all tool passing to AI SDK - tools are processed server-side only`);

  const hasTools = false;

  return await _streamText({
    model: provider.getModelInstance({
      model: modelDetails.name,
      serverEnv,
      apiKeys,
      providerSettings,
    }),
    system: systemPrompt,
    maxTokens: dynamicMaxTokens,
    messages: convertToCoreMessages(processedMessages as any),
    ...(hasTools ? { tools: allTools, toolChoice: 'auto' } : {}),
  });
}
